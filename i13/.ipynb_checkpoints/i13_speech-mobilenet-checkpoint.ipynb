{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "# File Processing\n",
    "import glob\n",
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "\n",
    "# Math\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Data Plotting and Visualizations\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn Metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "pd.options.display.max_rows = 40\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_audio_folder = './train/audio/'\n",
    "train_spect_folder = './train/spect/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The labels you will need to predict in Test are yes, no, up, down, left, right, on, off, stop, go. \n",
    "# Everything else should be considered either unknown or silence. \n",
    "# The folder _background_noise_ contains longer clips of \"silence\" that you can break up and use as training input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_labels = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#separate folder into unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subfolder_names_list = [x for x in os.listdir(train_spect_folder) if os.path.isdir(train_spect_folder + '/' + x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subfolder_names_list[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data - From Image Spectrograms -> Numpy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0 - folder name: zero - number of files: 2376\n",
      "index: 1 - folder name: six - number of files: 2369\n",
      "index: 2 - folder name: happy - number of files: 1742\n",
      "index: 3 - folder name: on - number of files: 2367\n",
      "index: 4 - folder name: left - number of files: 2353\n",
      "index: 5 - folder name: one - number of files: 2370\n",
      "index: 6 - folder name: no - number of files: 2375\n",
      "index: 7 - folder name: go - number of files: 2372\n",
      "index: 8 - folder name: _background_noise_ - number of files: 6\n",
      "index: 9 - folder name: off - number of files: 2357\n",
      "index: 10 - folder name: tree - number of files: 1733\n",
      "index: 11 - folder name: bed - number of files: 1713\n",
      "index: 12 - folder name: cat - number of files: 1733\n",
      "index: 13 - folder name: up - number of files: 2375\n",
      "index: 14 - folder name: eight - number of files: 2352\n",
      "index: 15 - folder name: marvin - number of files: 1746\n",
      "index: 16 - folder name: stop - number of files: 2380\n",
      "index: 17 - folder name: yes - number of files: 2377\n",
      "index: 18 - folder name: three - number of files: 2356\n",
      "index: 19 - folder name: down - number of files: 2359\n",
      "index: 20 - folder name: nine - number of files: 2364\n",
      "index: 21 - folder name: four - number of files: 2372\n",
      "index: 22 - folder name: seven - number of files: 2377\n",
      "index: 23 - folder name: sheila - number of files: 1734\n",
      "index: 24 - folder name: dog - number of files: 1746\n",
      "index: 25 - folder name: right - number of files: 2367\n",
      "index: 26 - folder name: two - number of files: 2373\n",
      "index: 27 - folder name: wow - number of files: 1745\n",
      "index: 28 - folder name: house - number of files: 1750\n",
      "index: 29 - folder name: bird - number of files: 1731\n",
      "index: 30 - folder name: five - number of files: 2357\n"
     ]
    }
   ],
   "source": [
    "all_images = []\n",
    "subfolder_lens = []\n",
    "for x in range(len(subfolder_names_list)):\n",
    "    subfolder_files = [x for x in os.listdir(train_spect_folder + subfolder_names_list[x]) if '.jpg' in x]\n",
    "    number_of_files = len(subfolder_files)\n",
    "    print(\"index: %d - folder name: %s - number of files: %d\" % (x, subfolder_names_list[x], number_of_files))\n",
    "    #number_of_files = 6\n",
    "    subfolder_lens.append(number_of_files)\n",
    "#     for y in range(number_of_files):\n",
    "#         image_path = train_spect_folder + subfolder_names_list[x] + '/' + subfolder_files[y]\n",
    "#         image = np.asarray(Image.open(image_path))\n",
    "#         image = np.append(image, x)\n",
    "#         all_images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2376,\n",
       " 2369,\n",
       " 1742,\n",
       " 2367,\n",
       " 2353,\n",
       " 2370,\n",
       " 2375,\n",
       " 2372,\n",
       " 6,\n",
       " 2357,\n",
       " 1733,\n",
       " 1713,\n",
       " 1733,\n",
       " 2375,\n",
       " 2352,\n",
       " 1746,\n",
       " 2380,\n",
       " 2377,\n",
       " 2356,\n",
       " 2359,\n",
       " 2364,\n",
       " 2372,\n",
       " 2377,\n",
       " 1734,\n",
       " 1746,\n",
       " 2367,\n",
       " 2373,\n",
       " 1745,\n",
       " 1750,\n",
       " 1731,\n",
       " 2357]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#subfolder_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_images = len(all_images)\n",
    "len_train_data = int(total_images *0.8)\n",
    "len_validation_data = int(total_images *0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_images = np.asarray(np.random.permutation(all_images))\n",
    "all_examples = all_images[:, :-1].reshape(-1, 96,96,3)\n",
    "all_labels = all_images[:, -1:]\n",
    "training_examples = all_examples[:len_train_data].astype(np.float32)\n",
    "validation_examples = all_examples[len_train_data:].astype(np.float32)\n",
    "training_labels = all_labels[:len_train_data]\n",
    "validation_labels = all_labels[len_train_data:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of original np array for all images:\n",
      "(155, 96, 96, 3)\n",
      "shape of original np array for all labels:\n",
      "(155,)\n",
      "\n",
      "train/validation split\n",
      "train len : 148\n",
      "validation len: 37\n",
      "\n",
      "training examples shape:\n",
      "(148, 96, 96, 3)\n",
      "training labels shape:\n",
      "(148, 1)\n",
      "validation examples shape:\n",
      "(38, 96, 96, 3)\n",
      "validation labels shape:\n",
      "(38, 1)\n"
     ]
    }
   ],
   "source": [
    "print('shape of original np array for all images:')\n",
    "print(all_images_np.shape)\n",
    "print('shape of original np array for all labels:')\n",
    "print(all_labels_np.shape)\n",
    "\n",
    "print(\"\\ntrain/validation split\")\n",
    "print('train len :', len_train_data)\n",
    "print('validation len:', len_validation_data)\n",
    "\n",
    "print('\\ntraining examples shape:')\n",
    "print(training_examples.shape)\n",
    "print('training labels shape:')\n",
    "print(training_labels.shape)\n",
    "print('validation examples shape:')\n",
    "print(validation_examples.shape)\n",
    "print('validation labels shape:')\n",
    "print(validation_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model and Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mobilenet_v2_35_model_fn(features, labels, mode, params):\n",
    "    module = hub.Module(\"https://tfhub.dev/google/imagenet/mobilenet_v2_035_96/feature_vector/1\")\n",
    "    input_layer = features[\"x\"]\n",
    "    outputs = module(input_layer)\n",
    "    print(\"outputs:\")\n",
    "    print(outputs.shape)\n",
    "\n",
    "    logits = tf.layers.dense(inputs=outputs, units=31)\n",
    "    print(\"flattened layer\")\n",
    "    print(logits.shape)\n",
    "    \n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    print(\"predictions generated\")\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    print(\"Calculate Loss (for both TRAIN and EVAL modes)\")\n",
    "    print(labels.shape)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    print(\"Loss calculated.\")\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=params['learning_rate'])\n",
    "        optimizer = tf.contrib.estimator.clip_gradients_by_norm(optimizer, 5.0)\n",
    "        print(\"minimizing loss\")\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])}\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_train_input_fn(data, targets, batch_size, num_epochs=None, shuffle=True):\n",
    "    input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x={\"x\": data},\n",
    "            y=targets,\n",
    "            batch_size=batch_size,\n",
    "            num_epochs=None,\n",
    "            shuffle=True)\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_predict_input_fn(data, targets, batch_size):\n",
    "    input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": data},\n",
    "        y=targets,\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_mobilenet_model(learning_rate, steps, batch_size,\n",
    "                    training_examples, training_targets, \n",
    "                    validation_examples, validation_targets):\n",
    "    periods = 10\n",
    "    steps_per_period = steps // periods \n",
    "    \n",
    "    train_input_fn = create_train_input_fn(training_examples, training_targets, batch_size)\n",
    "    train_predictions_fn = create_predict_input_fn(training_examples, training_targets, batch_size)\n",
    "    validation_predictions_fn = create_predict_input_fn(validation_examples, validation_targets, batch_size)\n",
    "    \n",
    "    classifier = tf.estimator.Estimator(\n",
    "        model_fn=mobilenet_v2_35_model_fn,\n",
    "        model_dir=\"./mobilenet_model_001_fn\",\n",
    "        params={\n",
    "            'learning_rate': learning_rate, \n",
    "        })\n",
    "\n",
    "    print(\"Training model...\")\n",
    "    print(\"LogLoss error (on validation data):\")\n",
    "    training_errors = []\n",
    "    validation_errors = []\n",
    "    train_accuracy_log = []\n",
    "    validation_accuracy_log = []\n",
    "    for period in range (0, periods):\n",
    "        #print(\"period %d\" % period)\n",
    "        classifier.train(\n",
    "            input_fn=train_input_fn,\n",
    "            steps=steps_per_period,\n",
    "            #hooks=[logging_hook]\n",
    "        )\n",
    "        \n",
    "        print(\"making training predictions\")\n",
    "        training_predictions = classifier.predict(input_fn=train_predictions_fn)\n",
    "        training_predictions_list = list(training_predictions)\n",
    "        #print(\"pulling out probabilities\")\n",
    "        training_probabilities = np.array([item['probabilities'] for item in training_predictions_list])\n",
    "        training_pred_class_id = np.array([item['classes'] for item in training_predictions_list])\n",
    "        training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id,31)\n",
    "\n",
    "        print(\"making validation predictions\")\n",
    "        validation_predictions = classifier.predict(input_fn=validation_predictions_fn)\n",
    "        validation_predictions_list = list(validation_predictions)\n",
    "        #print(\"pulling out probabilities\")\n",
    "        validation_probabilities = np.array([item['probabilities'] for item in validation_predictions_list])    \n",
    "        validation_pred_class_id = np.array([item['classes'] for item in validation_predictions_list])\n",
    "        validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,31)    \n",
    "\n",
    "        training_log_loss = metrics.log_loss(training_targets, training_pred_one_hot)\n",
    "        validation_log_loss = metrics.log_loss(validation_targets, validation_pred_one_hot)\n",
    "        \n",
    "        train_accuracy = metrics.accuracy_score(training_targets, training_pred_class_id)\n",
    "        validation_accuracy = metrics.accuracy_score(validation_targets, validation_pred_class_id)\n",
    "        print(\"  period %02d : %0.2f, %0.2f\" % (period, validation_log_loss, validation_accuracy))\n",
    "        \n",
    "        train_accuracy_log.append(train_accuracy)\n",
    "        validation_accuracy_log.append(validation_accuracy)\n",
    "        training_errors.append(training_log_loss)\n",
    "        validation_errors.append(validation_log_loss)\n",
    "    print(\"Model training finished.\")\n",
    "\n",
    "    _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*')))\n",
    "\n",
    "    final_predictions = classifier.predict(input_fn=validation_predictions_fn)\n",
    "    final_predictions = np.array([item['classes'] for item in final_predictions])\n",
    "\n",
    "    accuracy = metrics.accuracy_score(validation_targets, final_predictions)\n",
    "    print(\"Final accuracy (on validation data): %0.2f\" % accuracy)\n",
    "\n",
    "    plt.ylabel(\"LogLoss\")\n",
    "    plt.xlabel(\"Periods\")\n",
    "    plt.title(\"LogLoss vs. Periods\")\n",
    "    plt.plot(training_errors, label=\"training\")\n",
    "    plt.plot(validation_errors, label=\"validation\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Periods\")\n",
    "    plt.title(\"Accuracy vs. Periods\")\n",
    "    plt.plot(train_accuracy_log, label=\"accuracy\")\n",
    "    plt.plot(validation_accuracy_log, label=\"accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Output a plot of the confusion matrix.\n",
    "    cm = metrics.confusion_matrix(validation_targets, final_predictions)\n",
    "    # Normalize the confusion matrix by row (i.e by the number of samples in each class).\n",
    "    cm_normalized = cm.astype(\"float\") // cm.sum(axis=1)[:, np.newaxis]\n",
    "    ax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\n",
    "    ax.set_aspect(1)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.show()\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call to Execute Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "outputs:\n",
      "(10, 1280)\n",
      "flattened layer\n",
      "(10, 31)\n",
      "predictions generated\n",
      "Calculate Loss (for both TRAIN and EVAL modes)\n",
      "(10, 1)\n",
      "Loss calculated.\n",
      "minimizing loss\n",
      "making training predictions\n",
      "outputs:\n",
      "(?, 1280)\n",
      "flattened layer\n",
      "(?, 31)\n",
      "predictions generated\n",
      "making validation predictions\n",
      "outputs:\n",
      "(?, 1280)\n",
      "flattened layer\n",
      "(?, 31)\n",
      "predictions generated\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred contain different number of classes 24, 31. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [ 1  2  3  4  6  7  8  9 10 12 13 14 16 17 18 19 22 23 24 26 27 28 29 30]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-252-76889a40d6f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mobilenet_trained_model = train_mobilenet_model(\\n    learning_rate = 0.03,\\n    steps=10,\\n    batch_size=10,\\n    training_examples=training_examples,\\n    training_targets=training_labels,\\n    validation_examples=validation_examples,\\n    validation_targets=validation_labels) '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/girlybit/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2120\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2121\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/girlybit/anaconda3/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/girlybit/anaconda3/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m             \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-251-ab8ce54d9316>\u001b[0m in \u001b[0;36mtrain_mobilenet_model\u001b[1;34m(learning_rate, steps, batch_size, training_examples, training_targets, validation_examples, validation_targets)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mtraining_log_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_pred_one_hot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mvalidation_log_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_pred_one_hot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_pred_class_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/girlybit/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[1;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[0;32m   1684\u001b[0m                              \"y_true: {2}\".format(transformed_labels.shape[1],\n\u001b[0;32m   1685\u001b[0m                                                   \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1686\u001b[1;33m                                                   lb.classes_))\n\u001b[0m\u001b[0;32m   1687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1688\u001b[0m             raise ValueError('The number of classes in labels is different '\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred contain different number of classes 24, 31. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [ 1  2  3  4  6  7  8  9 10 12 13 14 16 17 18 19 22 23 24 26 27 28 29 30]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mobilenet_trained_model = train_mobilenet_model(\n",
    "    learning_rate = 0.03,\n",
    "    steps=10,\n",
    "    batch_size=10,\n",
    "    training_examples=training_examples,\n",
    "    training_targets=training_labels,\n",
    "    validation_examples=validation_examples,\n",
    "    validation_targets=validation_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
